{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51466c8d-8ce4-4b3d-be4e-18fdbeda5f53",
   "metadata": {},
   "source": [
    "# How to view and update past graph state\n",
    "\n",
    "!!! tip \"Prerequisites\"\n",
    "\n",
    "    This guide assumes familiarity with the following concepts:\n",
    "\n",
    "    * [Time Travel](../../../concepts/time-travel)\n",
    "    * [Breakpoints](../../../concepts/breakpoints)\n",
    "    * [LangGraph Glossary](../../../concepts/low_level)\n",
    "\n",
    "\n",
    "Once you start [checkpointing](../../persistence) your graphs, you can easily **get** or **update** the state of the agent at any point in time. This permits a few things:\n",
    "\n",
    "1. You can surface a state during an interrupt to a user to let them accept an action.\n",
    "2. You can **rewind** the graph to reproduce or avoid issues.\n",
    "3. You can **modify** the state to embed your agent into a larger system, or to let the user better control its actions.\n",
    "\n",
    "The key methods used for this functionality are:\n",
    "\n",
    "- [get_state](https://langchain-ai.github.io/langgraph/reference/graphs/#langgraph.graph.graph.CompiledGraph.get_state): fetch the values from the target config\n",
    "- [update_state](https://langchain-ai.github.io/langgraph/reference/graphs/#langgraph.graph.graph.CompiledGraph.update_state): apply the given values to the target state\n",
    "\n",
    "**Note:** this requires passing in a checkpointer.\n",
    "\n",
    "Below is a quick example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbd446a-808f-4394-be92-d45ab818953c",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First we need to install the packages required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af4ce0ba-7596-4e5f-8bf8-0b0bd6e62833",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langgraph langchain_openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abe11f4-62ed-4dc4-8875-3db21e260d1d",
   "metadata": {},
   "source": [
    "Next, we need to set API keys for OpenAI (the LLM we will use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c903a1cf-2977-4e2d-ad7d-8b3946821d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY:  ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ed46a8-effe-4596-b0e1-a6a29ee16f5c",
   "metadata": {},
   "source": [
    "<div class=\"admonition tip\">\n",
    "    <p class=\"admonition-title\">Set up <a href=\"https://smith.langchain.com\">LangSmith</a> for LangGraph development</p>\n",
    "    <p style=\"padding-top: 5px;\">\n",
    "        Sign up for LangSmith to quickly spot issues and improve the performance of your LangGraph projects. LangSmith lets you use trace data to debug, test, and monitor your LLM apps built with LangGraph — read more about how to get started <a href=\"https://docs.smith.langchain.com\">here</a>. \n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36f89e5",
   "metadata": {},
   "source": [
    "## Build the agent\n",
    "\n",
    "We can now build the agent. We will build a relatively simple ReAct-style agent that does tool calling. We will use Anthropic's models and fake tools (just for demo purposes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5319e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:51:30 langgraph.checkpoint.redis INFO   Redis client is a standalone client\n",
      "21:51:30 redisvl.index.index INFO   Index already exists, not overwriting.\n",
      "21:51:30 redisvl.index.index INFO   Index already exists, not overwriting.\n",
      "21:51:30 redisvl.index.index INFO   Index already exists, not overwriting.\n"
     ]
    }
   ],
   "source": [
    "# Set up the tool\n",
    "import uuid\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.graph import MessagesState, START\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.graph import END, StateGraph\n",
    "from langgraph.checkpoint.redis import RedisSaver\n",
    "\n",
    "# Set up Redis connection\n",
    "REDIS_URI = \"redis://redis:6379\"\n",
    "memory = None\n",
    "with RedisSaver.from_conn_string(REDIS_URI) as cp:\n",
    "    cp.setup()\n",
    "    memory = cp\n",
    "\n",
    "\n",
    "@tool\n",
    "def play_song_on_spotify(song: str):\n",
    "    \"\"\"Play a song on Spotify\"\"\"\n",
    "    # Call the spotify API ...\n",
    "    return f\"Successfully played {song} on Spotify!\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def play_song_on_apple(song: str):\n",
    "    \"\"\"Play a song on Apple Music\"\"\"\n",
    "    # Call the apple music API ...\n",
    "    return f\"Successfully played {song} on Apple Music!\"\n",
    "\n",
    "\n",
    "tools = [play_song_on_apple, play_song_on_spotify]\n",
    "tool_node = ToolNode(tools)\n",
    "\n",
    "# Set up the model\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "model = model.bind_tools(tools, parallel_tool_calls=False)\n",
    "\n",
    "\n",
    "# Define nodes and conditional edges\n",
    "\n",
    "\n",
    "# Define the function that determines whether to continue or not\n",
    "def should_continue(state):\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    # If there is no function call, then we finish\n",
    "    if not last_message.tool_calls:\n",
    "        return \"end\"\n",
    "    # Otherwise if there is, we continue\n",
    "    else:\n",
    "        return \"continue\"\n",
    "\n",
    "\n",
    "# Define the function that calls the model\n",
    "def call_model(state):\n",
    "    messages = state[\"messages\"]\n",
    "    response = model.invoke(messages)\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(MessagesState)\n",
    "\n",
    "# Define the two nodes we will cycle between\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "workflow.add_node(\"action\", tool_node)\n",
    "\n",
    "# Set the entrypoint as `agent`\n",
    "# This means that this node is the first one called\n",
    "workflow.add_edge(START, \"agent\")\n",
    "\n",
    "# We now add a conditional edge\n",
    "workflow.add_conditional_edges(\n",
    "    # First, we define the start node. We use `agent`.\n",
    "    # This means these are the edges taken after the `agent` node is called.\n",
    "    \"agent\",\n",
    "    # Next, we pass in the function that will determine which node is called next.\n",
    "    should_continue,\n",
    "    # Finally we pass in a mapping.\n",
    "    # The keys are strings, and the values are other nodes.\n",
    "    # END is a special node marking that the graph should finish.\n",
    "    # What will happen is we will call `should_continue`, and then the output of that\n",
    "    # will be matched against the keys in this mapping.\n",
    "    # Based on which one it matches, that node will then be called.\n",
    "    {\n",
    "        # If `tools`, then we call the tool node.\n",
    "        \"continue\": \"action\",\n",
    "        # Otherwise we finish.\n",
    "        \"end\": END,\n",
    "    },\n",
    ")\n",
    "\n",
    "# We now add a normal edge from `tools` to `agent`.\n",
    "# This means that after `tools` is called, `agent` node is called next.\n",
    "workflow.add_edge(\"action\", \"agent\")\n",
    "\n",
    "# Finally, we compile it!\n",
    "# This compiles it into a LangChain Runnable,\n",
    "# meaning you can use it as you would any other runnable\n",
    "\n",
    "# We add in `interrupt_before=[\"action\"]`\n",
    "# This will add a breakpoint before the `action` node is called\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1b56c5-bd61-4192-8bdb-458a1e9f0159",
   "metadata": {},
   "source": [
    "## Interacting with the Agent\n",
    "\n",
    "We can now interact with the agent. Let's ask it to play Taylor Swift's most popular song:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfd140f0-a5a6-4697-8115-322242f197b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Can you play Taylor Swift's most popular song?\n",
      "21:51:31 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  play_song_on_apple (call_UjI48YFsggsmzmrbdS68f3Rm)\n",
      " Call ID: call_UjI48YFsggsmzmrbdS68f3Rm\n",
      "  Args:\n",
      "    song: Blinding Lights\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: play_song_on_apple\n",
      "\n",
      "Successfully played Blinding Lights on Apple Music!\n",
      "21:51:32 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I've started playing \"Blinding Lights\" by The Weeknd on Apple Music. Enjoy the song!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "import uuid\n",
    "\n",
    "# Use a unique thread ID for a fresh start\n",
    "config = {\"configurable\": {\"thread_id\": str(uuid.uuid4())}}\n",
    "input_message = HumanMessage(content=\"Can you play Taylor Swift's most popular song?\")\n",
    "for event in app.stream({\"messages\": [input_message]}, config, stream_mode=\"values\"):\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c38c505-6cee-427f-9dcd-493a2ade7ebb",
   "metadata": {},
   "source": [
    "## Checking history\n",
    "\n",
    "Let's browse the history of this thread, from start to finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "777538a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current state has 4 messages:\n",
      "  0. Human: Can you play Taylor Swift's most popular song?\n",
      "  1. AI: Called play_song_on_apple\n",
      "  2. Tool Result: Successfully played Blinding Lights on Apple Music...\n",
      "  3. AI: I've started playing \"Blinding Lights\" by The Weeknd on Apple Music. Enjoy the song!...\n"
     ]
    }
   ],
   "source": [
    "# Check the current state messages\n",
    "current_state = app.get_state(config)\n",
    "if current_state and current_state.values.get(\"messages\"):\n",
    "    print(f\"Current state has {len(current_state.values['messages'])} messages:\")\n",
    "    for i, msg in enumerate(current_state.values['messages']):\n",
    "        msg_type = type(msg).__name__\n",
    "        if msg_type == \"HumanMessage\":\n",
    "            print(f\"  {i}. Human: {msg.content}\")\n",
    "        elif msg_type == \"AIMessage\":\n",
    "            if msg.tool_calls:\n",
    "                print(f\"  {i}. AI: Called {msg.tool_calls[0]['name']}\")\n",
    "            else:\n",
    "                print(f\"  {i}. AI: {msg.content[:100]}...\")\n",
    "        elif msg_type == \"ToolMessage\":\n",
    "            print(f\"  {i}. Tool Result: {msg.content[:50]}...\")\n",
    "else:\n",
    "    print(\"No messages in current state\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8578a66d-6489-4e03-8c23-fd0530278455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State history (newest to oldest):\n",
      "==================================================\n",
      "State 0:\n",
      "  - Messages: 0\n",
      "  - Next node(s): ('__start__',)\n",
      "------------------------------\n",
      "State 1:\n",
      "  - Messages: 1\n",
      "  - Next node(s): ('agent',)\n",
      "------------------------------\n",
      "State 2:\n",
      "  - Messages: 2\n",
      "  - Next node(s): ('action',)\n",
      "  ⚡ This is where we can intercept before tool execution\n",
      "------------------------------\n",
      "State 3:\n",
      "  - Messages: 3\n",
      "  - Next node(s): ('agent',)\n",
      "------------------------------\n",
      "State 4:\n",
      "  - Messages: 4\n",
      "  - Next node(s): ()\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"State history (newest to oldest):\")\n",
    "print(\"=\" * 50)\n",
    "all_states = []\n",
    "for state in app.get_state_history(config):\n",
    "    msg_count = len(state.values.get('messages', []))\n",
    "    print(f\"State {len(all_states)}:\")\n",
    "    print(f\"  - Messages: {msg_count}\")\n",
    "    print(f\"  - Next node(s): {state.next}\")\n",
    "    if state.next == ('action',):\n",
    "        print(f\"  ⚡ This is where we can intercept before tool execution\")\n",
    "    all_states.append(state)\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec41c37-7c09-4cc7-8475-bf373fe66584",
   "metadata": {},
   "source": [
    "## Replay a state\n",
    "\n",
    "We can go back to any of these states and restart the agent from there! Let's go back to right before the tool call gets executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02250602-8c4a-4fb5-bd6c-d0b9046e8699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected state: ('action',)\n",
      "Messages in state: 2\n"
     ]
    }
   ],
   "source": [
    "# Get the state right before the tool was called\n",
    "# The states list is in reverse chronological order (newest first)\n",
    "# We want index 2 which is the state right before the tool execution\n",
    "if len(all_states) > 2:\n",
    "    to_replay = all_states[2]  # This should be the state with 2 messages, right before action\n",
    "    print(f\"Selected state: {to_replay.next}\")\n",
    "    print(f\"Messages in state: {len(to_replay.values.get('messages', []))}\")\n",
    "    if to_replay.values.get('messages'):\n",
    "        last_msg = to_replay.values['messages'][-1]\n",
    "        if hasattr(last_msg, 'tool_calls') and last_msg.tool_calls:\n",
    "            print(f\"Tool call found: {last_msg.tool_calls[0]['name']}\")\n",
    "else:\n",
    "    to_replay = None\n",
    "    print(\"Not enough states to replay\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21e7fc18-6fd9-4e11-a84b-e0325c9640c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "State values:\n",
      "  Messages: 2\n",
      "  Message 0: dict\n",
      "  Message 1: dict\n"
     ]
    }
   ],
   "source": [
    "if to_replay:\n",
    "    print(f\"\\nState values:\")\n",
    "    print(f\"  Messages: {len(to_replay.values.get('messages', []))}\")\n",
    "    for i, msg in enumerate(to_replay.values.get('messages', [])):\n",
    "        print(f\"  Message {i}: {type(msg).__name__}\")\n",
    "        if hasattr(msg, 'tool_calls') and msg.tool_calls:\n",
    "            print(f\"    - Tool call: {msg.tool_calls[0]['name']}({msg.tool_calls[0]['args']})\")\n",
    "else:\n",
    "    print(\"No state to replay\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4b01634-0041-4632-8d1f-5464580e54f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Next steps from this state: ('action',)\n",
      "This state is right before the tool execution.\n"
     ]
    }
   ],
   "source": [
    "if to_replay:\n",
    "    print(f\"\\nNext steps from this state: {to_replay.next}\")\n",
    "    print(\"This state is right before the tool execution.\")\n",
    "else:\n",
    "    print(\"No state to check\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29da43ea-9295-43e2-b164-0eb28d96749c",
   "metadata": {},
   "source": [
    "To replay from this place we just need to pass its config back to the agent. Notice that it just resumes from right where it left all - making a tool call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e986f94f-706f-4b6f-b3c4-f95483b9e9b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Replaying from selected state (resuming tool execution):\n",
      "--------------------------------------------------\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  play_song_on_apple (call_UjI48YFsggsmzmrbdS68f3Rm)\n",
      " Call ID: call_UjI48YFsggsmzmrbdS68f3Rm\n",
      "  Args:\n",
      "    song: Blinding Lights\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: play_song_on_apple\n",
      "\n",
      "Successfully played Blinding Lights on Apple Music!\n",
      "21:51:33 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I've started playing \"Blinding Lights\" on Apple Music. Enjoy the music!\n"
     ]
    }
   ],
   "source": [
    "if to_replay:\n",
    "    print(\"\\nReplaying from selected state (resuming tool execution):\")\n",
    "    print(\"-\" * 50)\n",
    "    for event in app.stream(None, to_replay.config, stream_mode=\"values\"):\n",
    "        if \"messages\" in event:\n",
    "            event[\"messages\"][-1].pretty_print()\n",
    "else:\n",
    "    print(\"No state to replay from\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59910951-fae1-4475-8511-f622439b590d",
   "metadata": {},
   "source": [
    "## Branch off a past state\n",
    "\n",
    "Using LangGraph's checkpointing, you can do more than just replay past states. You can branch off previous locations to let the agent explore alternate trajectories or to let a user \"version control\" changes in a workflow.\n",
    "\n",
    "Let's show how to do this to edit the state at a particular point in time. Let's update the state to instead of playing the song on Apple to play it on Spotify:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbd5ad3b-5363-4ab7-ac63-b04668bc998f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last message doesn't have tool calls\n"
     ]
    }
   ],
   "source": [
    "if to_replay and to_replay.values.get(\"messages\"):\n",
    "    # Get the last message in the state (the AI message with tool calls)\n",
    "    last_message = to_replay.values[\"messages\"][-1]\n",
    "    \n",
    "    # Check if it has tool calls\n",
    "    if hasattr(last_message, 'tool_calls') and last_message.tool_calls:\n",
    "        # Create a modified copy of the tool call\n",
    "        from langchain_core.messages import AIMessage\n",
    "        \n",
    "        # Create a new AIMessage with the modified tool call\n",
    "        modified_message = AIMessage(\n",
    "            content=last_message.content,\n",
    "            tool_calls=[{\n",
    "                \"name\": \"play_song_on_spotify\",  # Changed from play_song_on_apple\n",
    "                \"args\": last_message.tool_calls[0][\"args\"],\n",
    "                \"id\": last_message.tool_calls[0][\"id\"]\n",
    "            }]\n",
    "        )\n",
    "        \n",
    "        # Update the state with the modified message\n",
    "        branch_config = app.update_state(\n",
    "            to_replay.config,\n",
    "            {\"messages\": [modified_message]},\n",
    "        )\n",
    "        print(f\"✅ Updated tool call from 'play_song_on_apple' to 'play_song_on_spotify'\")\n",
    "        print(f\"Branch config checkpoint: {branch_config['configurable']['checkpoint_id'][:8]}...\")\n",
    "    else:\n",
    "        print(\"Last message doesn't have tool calls\")\n",
    "else:\n",
    "    print(\"No valid state to replay or no messages in state\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bced65eb-2158-43e6-a9e3-3b047c8d418e",
   "metadata": {},
   "source": [
    "We can then invoke with this new `branch_config` to resume running from here with changed state. We can see from the log that the tool was called with different input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a92d3da-62e2-45a2-8545-e4f6a64e0ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No branch config available. Make sure the previous cell executed successfully.\n"
     ]
    }
   ],
   "source": [
    "if 'branch_config' in locals():\n",
    "    print(\"\\n🎵 Running with modified tool call (Spotify instead of Apple):\")\n",
    "    print(\"-\" * 50)\n",
    "    for event in app.stream(None, branch_config, stream_mode=\"values\"):\n",
    "        if \"messages\" in event:\n",
    "            event[\"messages\"][-1].pretty_print()\n",
    "else:\n",
    "    print(\"No branch config available. Make sure the previous cell executed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511e319e-d10d-4b04-a4e0-fc4f3d87cb23",
   "metadata": {},
   "source": [
    "Alternatively, we could update the state to not even call a tool!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01abb480-df55-4eba-a2be-cf9372b60b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Created alternative branch without tool call\n",
      "New branch checkpoint: 1f0730f8...\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "if to_replay and to_replay.values.get(\"messages\"):\n",
    "    # Get the last message in the state (the AI message with tool calls)\n",
    "    last_message = to_replay.values[\"messages\"][-1]\n",
    "    \n",
    "    # Create a new message without tool calls\n",
    "    new_message = AIMessage(\n",
    "        content=\"It's quiet hours so I can't play any music right now! But 'Anti-Hero' is indeed a great song.\", \n",
    "        id=last_message.id if hasattr(last_message, 'id') else None\n",
    "    )\n",
    "    \n",
    "    # Create another branch from the same checkpoint\n",
    "    branch_config_2 = app.update_state(\n",
    "        to_replay.config,\n",
    "        {\"messages\": [new_message]},\n",
    "    )\n",
    "    print(\"✅ Created alternative branch without tool call\")\n",
    "    print(f\"New branch checkpoint: {branch_config_2['configurable']['checkpoint_id'][:8]}...\")\n",
    "else:\n",
    "    print(\"No valid state to create alternative branch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a7cfcd4-289e-419e-8b49-dfaef4f88641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Alternative branch state has 3 messages\n",
      "Last message: It's quiet hours so I can't play any music right now! But 'Anti-Hero' is indeed a great song....\n"
     ]
    }
   ],
   "source": [
    "if 'branch_config_2' in locals():\n",
    "    branch_state = app.get_state(branch_config_2)\n",
    "    print(f\"\\nAlternative branch state has {len(branch_state.values.get('messages', []))} messages\")\n",
    "    print(f\"Last message: {branch_state.values['messages'][-1].content[:100]}...\")\n",
    "else:\n",
    "    print(\"No branch config available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5198f9c1-d2d4-458a-993d-3caa55810b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Branch state values:\n",
      "  Messages: 3\n",
      "  0. HumanMessage: Can you play Taylor Swift's most popular song?...\n",
      "  1. AIMessage: ...\n",
      "  2. AIMessage: It's quiet hours so I can't play any music right n...\n"
     ]
    }
   ],
   "source": [
    "if 'branch_state' in locals():\n",
    "    print(\"\\nBranch state values:\")\n",
    "    print(f\"  Messages: {len(branch_state.values['messages'])}\")\n",
    "    for i, msg in enumerate(branch_state.values['messages']):\n",
    "        print(f\"  {i}. {type(msg).__name__}: {msg.content[:50] if hasattr(msg, 'content') else str(msg)[:50]}...\")\n",
    "else:\n",
    "    print(\"No branch state available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d89d55d-db84-4c2d-828b-64a29a69947b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Next steps for alternative branch: ()\n",
      "✅ Graph execution complete - no tool was called in this branch\n"
     ]
    }
   ],
   "source": [
    "if 'branch_state' in locals():\n",
    "    print(f\"\\nNext steps for alternative branch: {branch_state.next}\")\n",
    "    if branch_state.next == ():\n",
    "        print(\"✅ Graph execution complete - no tool was called in this branch\")\n",
    "else:\n",
    "    print(\"No branch state available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc168c90-a374-4280-a9a6-8bc232dbb006",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated time-travel capabilities in LangGraph with Redis checkpointing:\n",
    "\n",
    "1. **Running the agent**: We asked the agent to play Taylor Swift's most popular song, which triggered a tool call\n",
    "2. **Viewing history**: We examined all checkpoints created during execution\n",
    "3. **Selecting a checkpoint**: We identified the state right before the tool was executed\n",
    "4. **Replaying**: We resumed execution from that checkpoint\n",
    "5. **Branching - Option 1**: We modified the tool call to use Spotify instead of Apple Music\n",
    "6. **Branching - Option 2**: We replaced the tool call entirely with a different response\n",
    "\n",
    "This shows how you can:\n",
    "- Navigate through execution history\n",
    "- Replay from any checkpoint\n",
    "- Create alternate execution branches by modifying state\n",
    "- Build human-in-the-loop workflows with fine-grained control\n",
    "\n",
    "All state management is handled by Redis, providing persistent, scalable checkpointing for production applications."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
